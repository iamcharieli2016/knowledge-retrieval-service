# æ¨¡å‹é€‰æ‹©æŒ‡å—

## ğŸ“Š å¯ç”¨æ¨¡å‹å¯¹æ¯”

### 1. CLIP æ¨¡å‹ï¼ˆæ¨è - å¤šæ¨¡æ€ï¼‰

**æ¨¡å‹åç§°**: `openai/clip-vit-base-patch32`

**æ”¯æŒåŠŸèƒ½**:
- âœ… **æ–‡æœ¬åµŒå…¥** - æ”¯æŒæ–‡æœ¬æ£€ç´¢
- âœ… **å›¾ç‰‡åµŒå…¥** - æ”¯æŒä»¥å›¾æœå›¾
- âœ… **è·¨æ¨¡æ€æ£€ç´¢** - æ–‡æœ¬æœå›¾ç‰‡ï¼Œå›¾ç‰‡æœæ–‡æœ¬

**ä¼˜ç‚¹**:
- åŒæ—¶æ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡
- å¯ä»¥è¿›è¡Œè·¨æ¨¡æ€æ£€ç´¢
- é€‚åˆå¤šåª’ä½“å†…å®¹æ£€ç´¢

**ç¼ºç‚¹**:
- æ¨¡å‹è¾ƒå¤§ï¼ˆçº¦ 600MBï¼‰
- æ–‡æœ¬æ£€ç´¢ç²¾åº¦ç•¥ä½äºä¸“ç”¨æ–‡æœ¬æ¨¡å‹
- éœ€è¦æ›´å¤šè®¡ç®—èµ„æº

**æœ€ä½³ä½¿ç”¨åœºæ™¯**:
- éœ€è¦å¤„ç†å›¾ç‰‡å’Œæ–‡æ¡£çš„æ··åˆåœºæ™¯
- éœ€è¦ä»¥å›¾æœå›¾åŠŸèƒ½
- éœ€è¦ç”¨æ–‡å­—æè¿°æœç´¢å›¾ç‰‡

**é…ç½®**:
```yaml
embedding:
  model_name: "openai/clip-vit-base-patch32"
  dimension: 512
  device: "cpu"  # æˆ– "mps" (Apple Silicon) / "cuda" (NVIDIA GPU)
```

---

### 2. Sentence Transformersï¼ˆçº¯æ–‡æœ¬ï¼‰

**æ¨¡å‹åç§°**: `sentence-transformers/all-MiniLM-L6-v2`

**æ”¯æŒåŠŸèƒ½**:
- âœ… **æ–‡æœ¬åµŒå…¥** - ä¸“æ³¨æ–‡æœ¬æ£€ç´¢
- âŒ ä¸æ”¯æŒå›¾ç‰‡

**ä¼˜ç‚¹**:
- æ¨¡å‹å°ï¼ˆçº¦ 90MBï¼‰
- ä¸‹è½½å¿«é€Ÿ
- æ–‡æœ¬æ£€ç´¢ç²¾åº¦é«˜
- èµ„æºå ç”¨å°‘

**ç¼ºç‚¹**:
- åªèƒ½å¤„ç†æ–‡æœ¬
- ä¸èƒ½å¤„ç†å›¾ç‰‡æ–‡ä»¶

**æœ€ä½³ä½¿ç”¨åœºæ™¯**:
- åªéœ€è¦æ–‡æ¡£æ£€ç´¢ï¼ˆPDFã€Wordã€TXTï¼‰
- èµ„æºå—é™çš„ç¯å¢ƒ
- å¿«é€ŸåŸå‹å¼€å‘

**é…ç½®**:
```yaml
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  dimension: 384
  device: "cpu"
```

---

### 3. å…¶ä»–å¯é€‰æ¨¡å‹

#### ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹
```yaml
# é€‚åˆä¸­æ–‡æ–‡æœ¬
embedding:
  model_name: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
  dimension: 384
```

#### æ›´å¤§çš„ CLIP æ¨¡å‹
```yaml
# æ›´é«˜ç²¾åº¦ï¼Œä½†æ›´æ…¢
embedding:
  model_name: "openai/clip-vit-large-patch14"
  dimension: 768
```

#### å°å‹ CLIP æ¨¡å‹
```yaml
# æ›´å¿«é€Ÿï¼Œä½†ç²¾åº¦ç•¥ä½
embedding:
  model_name: "openai/clip-vit-base-patch16"
  dimension: 512
```

---

## ğŸš€ å½“å‰é…ç½®

### å·²è®¾ç½®ä¸ºï¼šCLIP æ¨¡å‹

å½“å‰ç³»ç»Ÿé…ç½®ä½¿ç”¨ **`openai/clip-vit-base-patch32`**ï¼Œå¯ä»¥ï¼š

âœ… ä¸Šä¼ å¹¶æ£€ç´¢ PDFã€Wordã€TXT æ–‡æ¡£
âœ… ä¸Šä¼ å¹¶æ£€ç´¢ JPGã€PNGã€GIF ç­‰å›¾ç‰‡
âœ… ç”¨æ–‡æœ¬æœç´¢å›¾ç‰‡
âœ… ç”¨å›¾ç‰‡æœç´¢æ–‡æ¡£
âœ… ä»¥å›¾æœå›¾

---

## ğŸ”§ å¦‚ä½•åˆ‡æ¢æ¨¡å‹

### æ–¹æ³•ä¸€ï¼šä¿®æ”¹é…ç½®æ–‡ä»¶

ç¼–è¾‘ `config.yaml`ï¼š

```yaml
embedding:
  model_name: "ä½ æƒ³ç”¨çš„æ¨¡å‹åç§°"
  dimension: å¯¹åº”çš„ç»´åº¦
```

ç„¶åé‡å¯æœåŠ¡ï¼š
```bash
./start-backend.sh
```

### æ–¹æ³•äºŒï¼šé€šè¿‡ API åŠ¨æ€æ›´æ–°

```bash
curl -X POST http://localhost:8000/api/v1/config \
  -H "Content-Type: application/json" \
  -d '{
    "embedding_model": "sentence-transformers/all-MiniLM-L6-v2"
  }'
```

**æ³¨æ„**: åˆ‡æ¢æ¨¡å‹åï¼Œéœ€è¦é‡æ–°ä¸Šä¼ æ–‡ä»¶é‡æ–°ç”ŸæˆåµŒå…¥å‘é‡ã€‚

---

## ğŸ’¾ æ¨¡å‹ç¼“å­˜

é¦–æ¬¡ä½¿ç”¨æ¨¡å‹æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½å¹¶ç¼“å­˜åˆ°ï¼š
```
~/.cache/huggingface/hub/
```

åç»­å¯åŠ¨ä¼šç›´æ¥ä½¿ç”¨ç¼“å­˜ï¼Œæ— éœ€é‡æ–°ä¸‹è½½ã€‚

---

## ğŸŒ ä¸‹è½½åŠ é€Ÿ

### ä½¿ç”¨å›½å†…é•œåƒ

å¯åŠ¨è„šæœ¬å·²è‡ªåŠ¨é…ç½®ï¼š
```bash
export HF_ENDPOINT=https://hf-mirror.com
```

### æ‰‹åŠ¨è®¾ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰

```bash
# Linux/macOS
export HF_ENDPOINT=https://hf-mirror.com

# Windows (PowerShell)
$env:HF_ENDPOINT="https://hf-mirror.com"
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### ä½¿ç”¨ GPU åŠ é€Ÿ

#### Apple Silicon (M1/M2/M3)
```yaml
embedding:
  device: "mps"  # Metal Performance Shaders
```

#### NVIDIA GPU
```yaml
embedding:
  device: "cuda"
```

éœ€è¦å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorchï¼š
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

#### CPU
```yaml
embedding:
  device: "cpu"  # é»˜è®¤ï¼Œå…¼å®¹æ€§æœ€å¥½
```

---

## ğŸ“ æ¨¡å‹ä¸‹è½½å¤§å°å‚è€ƒ

| æ¨¡å‹ | å¤§å° | ä¸‹è½½æ—¶é—´* |
|------|------|----------|
| all-MiniLM-L6-v2 | ~90MB | 1-2 åˆ†é’Ÿ |
| clip-vit-base-patch32 | ~600MB | 5-10 åˆ†é’Ÿ |
| clip-vit-large-patch14 | ~1.7GB | 15-30 åˆ†é’Ÿ |
| paraphrase-multilingual | ~470MB | 5-10 åˆ†é’Ÿ |

*ä½¿ç”¨é•œåƒåŠ é€Ÿï¼Œå®é™…é€Ÿåº¦å–å†³äºç½‘ç»œ

---

## ğŸ¯ æ¨èé…ç½®

### åœºæ™¯ä¸€ï¼šåªå¤„ç†æ–‡æ¡£
```yaml
embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  dimension: 384
```

### åœºæ™¯äºŒï¼šæ–‡æ¡£ + å›¾ç‰‡ï¼ˆæ¨èï¼‰
```yaml
embedding:
  model_name: "openai/clip-vit-base-patch32"
  dimension: 512
```

### åœºæ™¯ä¸‰ï¼šä¸­æ–‡ä¸ºä¸»
```yaml
embedding:
  model_name: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
  dimension: 384
```

---

## â“ å¸¸è§é—®é¢˜

**Q: åˆ‡æ¢æ¨¡å‹åä¹‹å‰çš„æ•°æ®æ€ä¹ˆåŠï¼Ÿ**
A: éœ€è¦é‡æ–°ä¸Šä¼ æ–‡ä»¶ï¼Œå› ä¸ºä¸åŒæ¨¡å‹çš„å‘é‡ç»´åº¦å’Œè¯­ä¹‰ç©ºé—´ä¸åŒã€‚

**Q: å¯ä»¥åŒæ—¶ä½¿ç”¨å¤šä¸ªæ¨¡å‹å—ï¼Ÿ**
A: å¯ä»¥ï¼Œåœ¨ `config.yaml` ä¸­ä¸ºä¸åŒæ–‡ä»¶ç±»å‹é…ç½®ä¸åŒæ¨¡å‹ï¼š
```yaml
embedding:
  models:
    image:
      model_name: "openai/clip-vit-base-patch32"
    text:
      model_name: "sentence-transformers/all-MiniLM-L6-v2"
```

**Q: æ¨¡å‹ä¸‹è½½å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**
A: ä½¿ç”¨é•œåƒ `export HF_ENDPOINT=https://hf-mirror.com`

**Q: å¦‚ä½•çŸ¥é“æ¨¡å‹æ˜¯å¦æ”¯æŒå›¾ç‰‡ï¼Ÿ**
A: åªæœ‰ CLIP ç³»åˆ—æ¨¡å‹æ”¯æŒå›¾ç‰‡ï¼Œå…¶ä»–éƒ½æ˜¯çº¯æ–‡æœ¬æ¨¡å‹ã€‚

---

## ğŸ“š æ›´å¤šä¿¡æ¯

- [HuggingFace Models](https://huggingface.co/models)
- [Sentence Transformers](https://www.sbert.net/)
- [CLIP Paper](https://arxiv.org/abs/2103.00020)
